{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**Instituto Federal de Educação, Ciência e Tecnologia de Minas Gerais - Campus Ouro Preto**<br>\n",
    "**Especialização em Inteligência Artificial**<br>\n",
    "**Disciplina: Redes Neurais e Aprendizado Profundo**<br>\n",
    "**Profs.: Dr. Agnaldo Silva, Dr. Frederico Gadelha, Dra. Sílvia Almeida**<br>\n",
    "**Alunos:  Fernando Fernandes, Ivanete e Marco Antônio**\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O que é inteligência para você(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O conceito de inteligência está associado à capacidade humana de tomar decisões e resolver problemas; à capacidade de se adaptar a diferentes situações; à capacidade de aprender algo novo, a partir da detecção de padrões;*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Em sua opinião (ou na do grupo), o que aconteceria se alguém descobrisse como implementar uma IA mais abrangente (e.g., AGI) em um robô?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Em algumas tarefas, as máquinas já são capazes de ter um desempenho semelhante ou melhor do que o ser humano, por exemplo, no processamento e análise de dados e imagens. De qualquer forma, os modelos de inteligência artificial atuais são capazes de resolver tarefas específicas. No momento em que for possível o desenvolvimento e implantação de uma IA mais abrangente em um robô, principalmente, se (ou quando) alcançarmos uma AGI (Artificial General Intelligence), para alguns pesquisadores, estaremos diante de um risco à raça humana; para outros, esse é o propósito das pesquisas em Inteligência Artificial.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A partir da análise de um processo de destilação fracionada de petróleo observou-se que determinado óleo poderia ser classificado em duas classes de pureza {C1 e C2}, mediante a medição de três grandezas {x1, x2\n",
    "e x3} que representam algumas das propriedades físico-químicas do óleo. Para tanto, pretende-se utilizar um perceptron para executar a classificação automática dessas duas classes. Assim, baseadas nas informações\n",
    "coletadas do processo, formou-se o conjunto de treinamento em anexo1, tomando por convenção o valor –1 para óleo pertencente à classe C1 e o valor +1 para óleo pertencente à classe C2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daí, pede-se:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Execute dois treinamentos para a rede perceptron, inicializando-se o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_features, learning_rate=0.01, epochs=100):\n",
    "        self.num_features = num_features\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.random.rand(num_features + 1)  # initial random weights +1 for the bias term\n",
    "        self.initialWeights = self.weights\n",
    "        print(f'[INFO] \\tRandom initial weights: {self.weights}')\n",
    "\n",
    "    def predict(self, inputs): # activation function\n",
    "        summation = np.dot(inputs, self.weights[1:]) + self.weights[0] # activation potential: u\n",
    "        return 1 if summation >= 0 else -1 # Use of the bipolar step function\n",
    "\n",
    "    def train(self, training_data, labels):\n",
    "        hasError = True\n",
    "        for epoch in range(self.epochs):\n",
    "            #print(f'[INFO] Epoch: {epoch}')\n",
    "            hasError = False\n",
    "            for inputs, label in zip(training_data, labels):\n",
    "                prediction = self.predict(inputs) # return of activation function: y\n",
    "                if prediction != label:\n",
    "                    hasError = True\n",
    "                    update = self.learning_rate * (label - prediction) # eta * (dk - y)\n",
    "                    self.weights[1:] += update * inputs # update weights: w <- w + eta * (dk - y) * xk\n",
    "                    self.weights[0] += update # update activation limiar: tetha <- tetha + eta * (dk - y)\n",
    "                    #print(f'[INFO] Weights: {self.weights}')\n",
    "            if hasError == False:\n",
    "                print(f'[INFO] \\tConverged after: {epoch + 1} epochs.')\n",
    "                break\n",
    "        print(f'[INFO] \\tFinal weights: {self.weights}')\n",
    "        print(f'[INFO] \\tTotal of epochs: {epoch + 1}')\n",
    "    \n",
    "    def getInitialWeights(self):\n",
    "        return self.initialWeights\n",
    "\n",
    "    def getFinalWeights(self):\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] ###### Perceptron Implementation #######\n",
      "\n",
      "[INFO] Loading training dataset and labels...\n",
      "\t[INFO] OK!\n",
      "\n",
      "[INFO] Getting information about training dataset...\n",
      "[INFO] Training dataset: \n",
      "[[-0.6508  0.1097  4.0009]\n",
      " [-1.4492  0.8896  4.4005]\n",
      " [ 2.085   0.6876 12.071 ]\n",
      " [ 0.2626  1.1476  7.7985]\n",
      " [ 0.6418  1.0234  7.0427]\n",
      " [ 0.2569  0.673   8.3265]\n",
      " [ 1.1155  0.6043  7.4446]\n",
      " [ 0.0914  0.3399  7.0677]\n",
      " [ 0.0121  0.5256  4.6316]\n",
      " [-0.0429  0.466   5.4323]\n",
      " [ 0.434   0.687   8.2287]\n",
      " [ 0.2735  1.0287  7.1934]\n",
      " [ 0.4839  0.4851  7.485 ]\n",
      " [ 0.4089 -0.1267  5.5019]\n",
      " [ 1.4391  0.1614  8.5843]\n",
      " [-0.9115 -0.1973  2.1962]\n",
      " [ 0.3654  1.0475  7.4858]\n",
      " [ 0.2144  0.7515  7.1699]\n",
      " [ 0.2013  1.0014  6.5489]\n",
      " [ 0.6483  0.2183  5.8991]\n",
      " [-0.1147  0.2242  7.2435]\n",
      " [-0.797   0.8795  3.8762]\n",
      " [-1.0625  0.6366  2.4707]\n",
      " [ 0.5307  0.1285  5.6883]\n",
      " [-1.22    0.7777  1.7252]\n",
      " [ 0.3957  0.1076  5.6623]\n",
      " [-0.1013  0.5989  7.1812]\n",
      " [ 2.4482  0.9455 11.2095]\n",
      " [ 2.0149  0.6192 10.9263]\n",
      " [ 0.2012  0.2611  5.4631]]\n",
      "[INFO] Labels of training dataset: \n",
      "[[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] ###### Perceptron Implementation #######')\n",
    "print(f'\\n[INFO] Loading training dataset and labels...')\n",
    "file = open('tab_treinamento1.dat', 'r')\n",
    "results = list()\n",
    "l = list()\n",
    "\n",
    "for line in file:\n",
    "    columns = line.split()\n",
    "    columns = np.array(columns, dtype=float)\n",
    "    results.append(columns[:3])\n",
    "    l.append(columns[-1:])\n",
    "    \n",
    "training_data = np.array(results)\n",
    "labels = np.array(l)\n",
    "print(f'\\t[INFO] OK!')\n",
    "\n",
    "#training_data = np.array([[0.6508, 0.1097, 4.0009], [-1.4492, 0.8896, 4.4005], [2.085, 0.6876, 1.2071], [0.2626, 1.1476, 7.7985], [0.6418, 1.0234, 7.0427], [0.2569, 0.673, 8.3265], [1.1155, 0.6043, 7.4446], [0.0914, 0.3399, 7.0677], [0.0121, 0.5256, 4.6316], [-0.0429, 0.466, 5.4323], [0.434, 0.687, 8.2287], [0.2735, 1.0287, 7.1934], [0.4839, 0.4851, 7.485], [0.4089, -0.1267, 5.5019], [1.4391, 0.1614, 8.5843], [-0.9115,  -0.1973, 2.1962], [0.3654, 1.0475, 7.4858], [0.2144, 0.7515, 7.1699], [0.2013, 1.0014, 6.5489], [0.6483, 0.2183, 5.8991], [-0.1147, 0.2242, 7.2435], [-0.797, 0.8795, 3.8762], [-1.0625, 0.6366, 2.4707], [0.5307, 0.1285, 5.6883], [-1.22, 0.7777, 1.7252], [0.3957, 0.1076, 5.6623], [-0.1013, 0.5989, 7.1812], [2.4482, 0.9455, 11.2095], [2.0149, 0.6192, 10.9263], [0.2012, 0.2611, 5.4631]])\n",
    "#labels = np.array([-1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1])\n",
    "print(f'\\n[INFO] Getting information about training dataset...') \n",
    "print(f'[INFO] Training dataset: \\n{training_data}')\n",
    "print(f'[INFO] Labels of training dataset: \\n{labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Creating a Perceptron...\n",
      "[INFO] \tRandom initial weights: [0.17736342 0.15638614 0.47744044 0.1209934 ]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Creating a Perceptron\n",
    "print(f'\\n[INFO] Creating a Perceptron...')\n",
    "number_of_epochs = 10000\n",
    "perceptron1 = Perceptron(num_features=3, learning_rate=0.01, epochs=number_of_epochs)\n",
    "print(f'[INFO] \\tOK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Getting information about training dataset...\n",
      "[INFO] \tTraining dataset size = 30\n",
      "[INFO] \tLabels size = 30\n",
      "[INFO] \tLimit of epochs: 10000\n",
      "\n",
      "[INFO] Training the Perceptron 1...\n",
      "[INFO] \tConverged after: 333 epochs.\n",
      "[INFO] \tFinal weights: [ 2.93736342  1.41135414  2.43657844 -0.7023866 ]\n",
      "[INFO] \tTotal of epochs: 333\n",
      "\t[INFO] OK!\n"
     ]
    }
   ],
   "source": [
    "# Training the perceptron 1\n",
    "print(f'\\n[INFO] Getting information about training dataset...')\n",
    "print(f'[INFO] \\tTraining dataset size = {training_data.shape[0]}')\n",
    "print(f'[INFO] \\tLabels size = {labels.shape[0]}')\n",
    "print(f'[INFO] \\tLimit of epochs: {number_of_epochs}')\n",
    "print(f'\\n[INFO] Training the Perceptron 1...')\n",
    "perceptron1.train(training_data, labels)\n",
    "\n",
    "initialWeights = perceptron1.getInitialWeights()\n",
    "finalWeights = perceptron1.getFinalWeights()\n",
    "print(f'\\t[INFO] OK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Creating a new Perceptron...\n",
      "[INFO] \tRandom initial weights: [0.44467875 0.60329962 0.69505087 0.33930767]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Creating a new Perceptron\n",
    "print(f'\\n[INFO] Creating a new Perceptron...')\n",
    "number_of_epochs = 10000\n",
    "perceptron2 = Perceptron(num_features=3, learning_rate=0.01, epochs=number_of_epochs)\n",
    "print(f'[INFO] \\tOK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Getting information about training dataset...\n",
      "[INFO] \tTraining dataset size = 30\n",
      "[INFO] \tLabels size = 30\n",
      "[INFO] \tLimit of epochs: 10000\n",
      "\n",
      "[INFO] Training the Perceptron 2...\n",
      "[INFO] \tConverged after: 386 epochs.\n",
      "[INFO] \tFinal weights: [ 3.06467875  1.55732162  2.47131887 -0.73088233]\n",
      "[INFO] \tTotal of epochs: 386\n",
      "\t[INFO] OK!\n"
     ]
    }
   ],
   "source": [
    "# Training the perceptron 2\n",
    "print(f'\\n[INFO] Getting information about training dataset...')\n",
    "print(f'[INFO] \\tTraining dataset size = {training_data.shape[0]}')\n",
    "print(f'[INFO] \\tLabels size = {labels.shape[0]}')\n",
    "print(f'[INFO] \\tLimit of epochs: {number_of_epochs}')\n",
    "print(f'\\n[INFO] Training the Perceptron 2...')\n",
    "perceptron2.train(training_data, labels)\n",
    "\n",
    "print(f'\\t[INFO] OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Registre os resultados dos dois treinamentos na tabela a seguir:\n",
    "\n",
    "Tabela 1 - Resultados dos treinamentos (**tab_treinamento1.dat**):\n",
    "<table border=\"1\">\n",
    "\t<tr>\n",
    "\t\t<td rowspan=\"2\">Treinamento</td>\n",
    "\t\t<td colspan=\"4\">Vetor de Pesos Inicial</td>\n",
    "\t\t<td colspan=\"4\">Vetor de Pesos Final</td>\n",
    "\t\t<td rowspan=\"2\"> Número de Épocas</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>b</td>\n",
    "\t\t<td>w1</td>\n",
    "\t\t<td>w2</td>\n",
    "\t\t<td>w3</td>\n",
    "\t\t<td>b</td>\n",
    "\t\t<td>w1</td>\n",
    "\t\t<td>w2</td>\n",
    "\t\t<td>w3</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>1º (T1)</td>\n",
    "\t\t<td>0.1773634</td>\n",
    "\t\t<td>0.15638614</td>\n",
    "\t\t<td>0.47744044</td>\n",
    "\t\t<td>0.1209934</td>\n",
    "\t\t<td>2.93736342</td>\n",
    "\t\t<td>1.41135414</td>\n",
    "\t\t<td>2.43657844</td>\n",
    "\t\t<td>-0.7023866</td>\n",
    "\t\t<td>333</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>2º (T1)</td>\n",
    "\t\t<td>0.44467875</td>\n",
    "\t\t<td>0.15638614</td>\n",
    "\t\t<td>0.69505087</td>\n",
    "\t\t<td>0.33930767</td>\n",
    "\t\t<td>3.06467875</td>\n",
    "\t\t<td>1.55732162</td>\n",
    "\t\t<td>2.47131887</td>\n",
    "\t\t<td>-0.73088233</td>\n",
    "\t\t<td>386</td>\n",
    "\t</tr>\n",
    "</table>\n",
    "\n",
    "*Nota: os valores atuais dessa tabela se referem ao últimos treinamentos realizados. Caso os trechos de código acima sejam executados novamente, necessita-se atualizar a tabela.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Após o treinamento do perceptron, aplique-o na classificação automática de novas amostras de óleo (ver arquivo tab_teste1.dat), indicando-se na tabela seguinte os resultados das saídas (Classes) referentes aos dois processos de treinamento realizados no item a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading testing dataset...\n",
      "\t[INFO] OK!\n",
      "\n",
      "[INFO] Getting information about testing dataset...\n",
      "[INFO] Testing dataset: \n",
      "[[-0.3565  0.062   5.9891]\n",
      " [-0.7842  1.1267  5.5912]\n",
      " [ 0.3012  0.5611  5.8234]\n",
      " [ 0.7757  1.0648  8.0677]\n",
      " [ 0.157   0.8028  6.304 ]\n",
      " [-0.7014  1.0316  3.6005]\n",
      " [ 0.3748  0.1536  6.1537]\n",
      " [-0.692   0.9404  4.4058]\n",
      " [-1.397   0.7141  4.9263]\n",
      " [-1.8842 -0.2805  1.2548]]\n",
      "[INFO] \tTesting dataset size = 10\n"
     ]
    }
   ],
   "source": [
    "# Testing dataset\n",
    "# test_data = np.array([[0.6508, 0.1097, 4.0009], [-1.4492, 0.8896, 4.4005], [2.085, 0.6876, 1.2071], [0.2626, 1.1476, 7.7985], [0.6418, 1.0234, 7.0427], [0.2569, 0.673, 8.3265], [1.1155, 0.6043, 7.4446], [0.0914, 0.3399, 7.0677], [0.0121, 0.5256, 4.6316], [-0.0429, 0.466, 5.4323], [0.434, 0.687, 8.2287], [0.2735, 1.0287, 7.1934], [0.4839, 0.4851, 7.485], [0.4089, -0.1267, 5.5019], [1.4391, 0.1614, 8.5843], [-0.9115,  -0.1973, 2.1962], [0.3654, 1.0475, 7.4858], [0.2144, 0.7515, 7.1699], [0.2013, 1.0014, 6.5489], [0.6483, 0.2183, 5.8991], [-0.1147, 0.2242, 7.2435], [-0.797, 0.8795, 3.8762], [-1.0625, 0.6366, 2.4707], [0.5307, 0.1285, 5.6883], [-1.22, 0.7777, 1.7252], [0.3957, 0.1076, 5.6623], [-0.1013, 0.5989, 7.1812], [2.4482, 0.9455, 11.2095], [2.0149, 0.6192, 10.9263], [0.2012, 0.2611, 5.4631]])\n",
    "\n",
    "# Testing the perceptron\n",
    "print(f'\\n[INFO] Loading testing dataset...')\n",
    "file = open('tab_teste1.dat', 'r')\n",
    "results = list()\n",
    "\n",
    "for line in file:\n",
    "    columns = line.split()\n",
    "    columns = np.array(columns, dtype=float)\n",
    "    results.append(columns[:])\n",
    "    \n",
    "testing_data = np.array(results)\n",
    "print(f'\\t[INFO] OK!')\n",
    "\n",
    "print(f'\\n[INFO] Getting information about testing dataset...') \n",
    "print(f'[INFO] Testing dataset: \\n{testing_data}')   \n",
    "# print(f'[INFO] \\tTesting dataset size = {training_data.shape[0]}')\n",
    "print(f'[INFO] \\tTesting dataset size = {testing_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running testing data with Perceptron 1...\n",
      "[INFO] \tInput: [-0.3565  0.062   5.9891] -> Output: -1\n",
      "[INFO] \tInput: [-0.7842  1.1267  5.5912] -> Output: 1\n",
      "[INFO] \tInput: [0.3012 0.5611 5.8234] -> Output: 1\n",
      "[INFO] \tInput: [0.7757 1.0648 8.0677] -> Output: 1\n",
      "[INFO] \tInput: [0.157  0.8028 6.304 ] -> Output: 1\n",
      "[INFO] \tInput: [-0.7014  1.0316  3.6005] -> Output: 1\n",
      "[INFO] \tInput: [0.3748 0.1536 6.1537] -> Output: -1\n",
      "[INFO] \tInput: [-0.692   0.9404  4.4058] -> Output: 1\n",
      "[INFO] \tInput: [-1.397   0.7141  4.9263] -> Output: -1\n",
      "[INFO] \tInput: [-1.8842 -0.2805  1.2548] -> Output: -1\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] Running testing data with Perceptron 1...')\n",
    "# for inputs in training_data:\n",
    "for inputs in testing_data:\n",
    "    result = perceptron1.predict(inputs)\n",
    "    print(f\"[INFO] \\tInput: {inputs} -> Output: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running testing data with Perceptron 2...\n",
      "[INFO] \tInput: [-0.3565  0.062   5.9891] -> Output: -1\n",
      "[INFO] \tInput: [-0.7842  1.1267  5.5912] -> Output: 1\n",
      "[INFO] \tInput: [0.3012 0.5611 5.8234] -> Output: 1\n",
      "[INFO] \tInput: [0.7757 1.0648 8.0677] -> Output: 1\n",
      "[INFO] \tInput: [0.157  0.8028 6.304 ] -> Output: 1\n",
      "[INFO] \tInput: [-0.7014  1.0316  3.6005] -> Output: 1\n",
      "[INFO] \tInput: [0.3748 0.1536 6.1537] -> Output: -1\n",
      "[INFO] \tInput: [-0.692   0.9404  4.4058] -> Output: 1\n",
      "[INFO] \tInput: [-1.397   0.7141  4.9263] -> Output: -1\n",
      "[INFO] \tInput: [-1.8842 -0.2805  1.2548] -> Output: -1\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] Running testing data with Perceptron 2...')\n",
    "# for inputs in training_data:\n",
    "for inputs in testing_data:\n",
    "    result = perceptron2.predict(inputs)\n",
    "    print(f\"[INFO] \\tInput: {inputs} -> Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela 2 - Resultados com as saídas das saída (classes) para os dados de teste (**tab_teste1.dat**):\n",
    "\n",
    "<table border=\"1\">\n",
    "\t<tr>\n",
    "\t\t<td>Amostra</td>\n",
    "\t\t<td>x1</td>\n",
    "\t\t<td>x2</td>\n",
    "\t\t<td>x3</td>\n",
    "\t\t<td>y (T1)</td>\n",
    "\t\t<td>y (T2)</td>        \n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>-0.3565</td>\n",
    "\t\t<td>0.0620</td>\n",
    "\t\t<td>5.9891</td>\n",
    "\t\t<td>-1</td>\n",
    "\t\t<td>-1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>2</td>\n",
    "\t\t<td>-0.7842</td>\n",
    "\t\t<td>1.1267</td>\n",
    "\t\t<td>5.5912</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>3</td>\n",
    "\t\t<td>0.3012</td>\n",
    "\t\t<td>0.5611</td>\n",
    "\t\t<td>5.8234</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>4</td>\n",
    "\t\t<td>0.7757</td>\n",
    "\t\t<td>1.0648</td>\n",
    "\t\t<td>8.0677</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>5</td>\n",
    "\t\t<td>0.157</td>\n",
    "\t\t<td>0.8028</td>\n",
    "\t\t<td>6.304</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>6</td>\n",
    "\t\t<td>-0.7014</td>\n",
    "\t\t<td>1.0316</td>\n",
    "\t\t<td>3.6005</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>            \n",
    "\t<tr>\n",
    "\t\t<td>7</td>\n",
    "\t\t<td>0.3748</td>\n",
    "\t\t<td>0.1536</td>\n",
    "\t\t<td>6.1537</td>\n",
    "\t\t<td>-1</td>\n",
    "\t\t<td>-1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>8</td>\n",
    "\t\t<td>-0.692</td>\n",
    "\t\t<td>0.9404</td>\n",
    "\t\t<td>4.4058</td>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>9</td>\n",
    "\t\t<td>-1.397</td>\n",
    "\t\t<td>0.7141</td>\n",
    "\t\t<td>4.9263</td>\n",
    "\t\t<td>-1</td>\n",
    "\t\t<td>-1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>10</td>\n",
    "\t\t<td>-1.8842</td>\n",
    "\t\t<td>-0.2805</td>\n",
    "\t\t<td>1.2548</td>\n",
    "\t\t<td>-1</td>\n",
    "\t\t<td>-1</td>\n",
    "\t</tr>                \n",
    "</table>\n",
    "\n",
    "*Nota: os valores atuais dessa tabela se referem ao últimos testes realizados. Caso os trechos de código acima sejam executados novamente, necessita-se atualizar a tabela.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Explique por que o número de épocas de treinamento varia a cada vez que se executa o treinamento do perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O número de épocas necessárias para a convergência do processo de treinamento varia conforme os valores iniciais dos pesos e do limiar de ativação. Esses valores iniciais definem quão longe da fronteira de seperação o treinamento inicia o ajuste do modelo. Se os valores iniciais atribuídos aos pesos e ao limiar de ativação são definidos aleatoriamente, a cada execução do treinamento, o número de épocas para a convergência normalmente é diferente.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Qual é a principal limitação do perceptron quando aplicado em problemas de classificação de padrões?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Os perceptrons são um tipo de rede neurais apropriada para tarefa de classificação de padrões em que as classes são linearmente separáveis. Por isso, para problemas não linearmente separáveis utilizando perceptrons, é necessário especificar um número máximo de épocas de treinamento.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Um sistema de gerenciamento automático de controle de duas válvulas, situado a 500 metros de um processo industrial, envia um sinal codificado constituído de quatro grandezas {x1, x2, x3 e x4} que são necessárias para o ajuste de cada uma das válvulas. Conforme mostra a figura abaixo, a mesma via de comunicação é utilizada para acionamento de ambas as válvulas, sendo que o  comutador localizado próximo das válvulas deve decidir se o sinal é para a válvula A ou B. Porém, durante a transmissão, os sinais sofrem interferências que alteram o conteúdo das informações transmitidas. Para resolver este problema, treinar-se-á uma rede ADALINE para classificar os sinais ruidosos, que informará ao sistema comutador se os dados\n",
    "devem ser encaminhados para o comando de ajuste da válvula A ou B.\n",
    "Assim, baseado nas medições dos sinais já com ruídos, formou-se o conjunto de treinamento em anexo2, tomando por convenção o valor –1 para os sinais que devem ser encaminhados para o ajuste da válvula A e o valor +1 se os mesmos devem ser enviados para a válvula B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daí, pede-se:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Execute 2 treinamentos para a rede ADALINE inicializando o vetor de pesos em cada treinamento com valores aleatórios entre zero e um de tal forma que os elementos do vetor de pesos iniciais não sejam os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Adaline:\n",
    "    def __init__(self, num_features, learning_rate=0.01, epochs=100, epsilon=1e-5):\n",
    "        self.num_features = num_features\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.weights = np.random.rand(num_features + 1)  # initial random weights +1 for the bias term\n",
    "        print(f'[INFO] \\tRandom initial weights: {self.weights}')\n",
    "\n",
    "    def predict(self, inputs): # activation function\n",
    "        activation = np.dot(inputs, self.weights[1:]) + self.weights[0] # activation potential: u\n",
    "        return 1 if activation >= 0 else -1  # Use of the bipolar step function\n",
    "\n",
    "    def train(self, training_data, targets):\n",
    "        mse = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            total_error = 0\n",
    "            #print(f'[INFO] Epoch: {epoch}')\n",
    "            for inputs, target in zip(training_data, targets):\n",
    "                activation = self.predict(inputs) # return of activation function: y\n",
    "                error = target - activation\n",
    "                self.weights[1:] += self.learning_rate * error * inputs\n",
    "                self.weights[0] += self.learning_rate * error\n",
    "                total_error += error ** 2\n",
    "            mse = total_error / len(targets)\n",
    "            if mse < self.epsilon:\n",
    "                print(f'[INFO] \\tConverged after: {epoch + 1} epochs.')\n",
    "                break\n",
    "        print(f'[INFO] \\tFinal weights: {self.weights}') \n",
    "        print(f'[INFO] \\tTotal of epochs: {epoch + 1}')\n",
    "        print(f'[INFO] \\tMean square error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] ###### Adaline Implementation #######\n",
      "\n",
      "[INFO] Loading training dataset and targets...\n",
      "[INFO] \tOK!\n",
      "[INFO] \tTraining dataset: \n",
      "[[ 4.3290e-01 -1.3719e+00  7.0220e-01 -8.5350e-01]\n",
      " [ 3.0240e-01  2.2860e-01  8.6300e-01  2.7909e+00]\n",
      " [ 1.3490e-01 -6.4450e-01  1.0530e+00  5.6870e-01]\n",
      " [ 3.3740e-01 -1.7163e+00  3.6700e-01 -6.2830e-01]\n",
      " [ 1.1434e+00 -4.8500e-02  6.6370e-01  1.2606e+00]\n",
      " [ 1.3749e+00 -5.0710e-01  4.4640e-01  1.3009e+00]\n",
      " [ 7.2210e-01 -7.5870e-01  7.6810e-01 -5.5920e-01]\n",
      " [ 4.4030e-01 -8.0720e-01  5.1540e-01 -3.1290e-01]\n",
      " [-5.2310e-01  3.5480e-01  2.5380e-01  1.5776e+00]\n",
      " [ 3.2550e-01 -2.0000e+00  7.1120e-01 -1.1209e+00]\n",
      " [ 5.8240e-01  1.3915e+00 -2.2910e-01  4.1735e+00]\n",
      " [ 1.3400e-01  6.0810e-01  4.4500e-01  3.2230e+00]\n",
      " [ 1.4800e-01 -2.9880e-01  4.7780e-01  8.6490e-01]\n",
      " [ 7.3590e-01  1.8690e-01 -8.7200e-02  2.3584e+00]\n",
      " [ 7.1150e-01 -1.1469e+00  3.3940e-01  9.5730e-01]\n",
      " [ 8.2510e-01 -1.2840e+00  8.4520e-01  1.2382e+00]\n",
      " [ 1.5690e-01  3.7120e-01  8.8250e-01  1.7633e+00]\n",
      " [ 3.3000e-03  6.8350e-01  5.3890e-01  2.8249e+00]\n",
      " [ 4.2430e-01  8.3130e-01  2.6340e-01  3.5855e+00]\n",
      " [ 1.0490e+00  1.3260e-01  9.1380e-01  1.9792e+00]\n",
      " [ 1.4276e+00  5.3310e-01 -1.4500e-02  3.7286e+00]\n",
      " [ 5.9710e-01  1.4865e+00  2.9040e-01  4.6069e+00]\n",
      " [ 8.4750e-01  2.1479e+00  3.1790e-01  5.8235e+00]\n",
      " [ 1.3967e+00 -4.1710e-01  6.4430e-01  1.3927e+00]\n",
      " [ 4.4000e-03  1.5378e+00  6.0990e-01  4.7755e+00]\n",
      " [ 2.2010e-01 -5.6680e-01  5.1500e-02  7.8290e-01]\n",
      " [ 6.3000e-01 -1.2480e+00  8.5910e-01  8.0930e-01]\n",
      " [-2.4790e-01  8.9600e-01  5.4700e-02  1.7381e+00]\n",
      " [-3.0880e-01 -9.2900e-02  8.6590e-01  1.5483e+00]\n",
      " [-5.1800e-01  1.4974e+00  5.4530e-01  2.3993e+00]\n",
      " [ 6.8330e-01  8.2660e-01  8.2900e-02  2.8864e+00]\n",
      " [ 4.3530e-01 -1.4066e+00  4.2070e-01 -4.8790e-01]\n",
      " [-1.0690e-01 -3.2329e+00  1.8560e-01 -2.4572e+00]\n",
      " [ 4.6620e-01  6.2610e-01  7.3040e-01  3.4370e+00]\n",
      " [ 8.2980e-01 -1.4089e+00  3.1190e-01  1.3235e+00]]\n",
      "[INFO] \tTargets of training dataset: \n",
      "[[ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] ###### Adaline Implementation #######')\n",
    "print(f'\\n[INFO] Loading training dataset and targets...')\n",
    "file = open('tab_treinamento2.dat', 'r')\n",
    "results = list()\n",
    "t = list()\n",
    "\n",
    "for line in file:\n",
    "    columns = line.split()\n",
    "    columns = np.array(columns, dtype=float)\n",
    "    results.append(columns[:4])\n",
    "    t.append(columns[-1:])\n",
    "    \n",
    "training_data = np.array(results)\n",
    "targets = np.array(t)\n",
    "print(f'[INFO] \\tOK!')\n",
    "\n",
    "#training_data = np.array([[4.3290000e-01, -1.3719000e+00, 7.0220000e-01, -8.5350000e-01],[3.0240000e-01, 2.2860000e-01, 8.6300000e-01, 2.7909000e+00],[1.3490000e-01, -6.4450000e-01, 1.0530000e+00, 5.6870000e-01],[3.3740000e-01, -1.7163000e+00, 3.6700000e-01, -6.2830000e-01],[1.1434000e+00, -4.8500000e-02, 6.6370000e-01, 1.2606000e+00],[1.3749000e+00, -5.0710000e-01, 4.4640000e-01, 1.3009000e+00],[7.2210000e-01, -7.5870000e-01, 7.6810000e-01, -5.5920000e-01],[4.4030000e-01, -8.0720000e-01, 5.1540000e-01, -3.1290000e-01],[-5.2310000e-01, 3.5480000e-01, 2.5380000e-01, 1.5776000e+00],[3.2550000e-01, -2.0000000e+00, 7.1120000e-01  -1.1209000e+00],[5.8240000e-01, 1.3915000e+00, -2.2910000e-01, 4.1735000e+00],[1.3400000e-01, 6.0810000e-01, 4.4500000e-01, 3.2230000e+00],[1.4800000e-01, -2.9880000e-01, 4.7780000e-01, 8.6490000e-01],[7.3590000e-01, 1.8690000e-01, -8.7200000e-02, 2.3584000e+00],[7.1150000e-01, -1.1469000e+00, 3.3940000e-01, 9.5730000e-01],[8.2510000e-01, -1.2840000e+00, 8.4520000e-01, 1.2382000e+00],[1.5690000e-01, 3.7120000e-01, 8.8250000e-01, 1.7633000e+00],[3.3000000e-03, 6.8350000e-01, 5.3890000e-01, 2.8249000e+00],[4.2430000e-01, 8.3130000e-01, 2.6340000e-01, 3.5855000e+00],[1.0490000e+00, 1.3260000e-01, 9.1380000e-01, 1.9792000e+00],[1.4276000e+00, 5.3310000e-01, -1.4500000e-02, 3.7286000e+00],[5.9710000e-01, 1.4865000e+00, 2.9040000e-01, 4.6069000e+00],[8.4750000e-01, 2.1479000e+00, 3.1790000e-01, 5.8235000e+00],[1.3967000e+00, -4.1710000e-01, 6.4430000e-01, 1.3927000e+00],[4.4000000e-03, 1.5378000e+00, 6.0990000e-01, 4.7755000e+00],[2.2010000e-01, -5.6680000e-01, 5.1500000e-02, 7.8290000e-01],[6.3000000e-01, -1.2480000e+00, 8.5910000e-01, 8.0930000e-01],[-2.4790000e-01, 8.9600000e-01, 5.4700000e-02, 1.7381000e+00],[-3.0880000e-01, -9.2900000e-02, 8.6590000e-01, 1.5483000e+00],[-5.1800000e-01, 1.4974000e+00, 5.4530000e-01, 2.3993000e+00],[6.8330000e-01, 8.2660000e-01, 8.2900000e-02, 2.8864000e+00],[4.3530000e-01, -1.4066000e+00, 4.2070000e-01, -4.8790000e-01],[-1.0690000e-01, -3.2329000e+00, 1.8560000e-01, -2.4572000e+00],[4.6620000e-01, 6.2610000e-01, 7.3040000e-01, 3.4370000e+00], [8.2980000e-01, -1.4089000e+00, 3.1190000e-01, 1.3235000e+00]])\n",
    "# targets = np.array([1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00, -1.0000000e+00, 1.0000000e+00, -1.0000000e+00, -1.0000000e+00, 1.0000000e+00, 1.0000000e+00, -1.0000000e+00, -1.0000000e+00, 1.0000000e+00, -1.0000000e+00, -1.0000000e+00, 1.0000000e+00, 1.0000000e+00, -1.0000000e+00, -1.0000000e+00, 1.0000000e+00, -1.0000000e+00, 1.0000000e+00, -1.0000000e+00, 1.0000000e+00, -1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00, -1.0000000e+00, -1.0000000e+00, -1.0000000e+00])\n",
    "print(f'[INFO] \\tTraining dataset: \\n{training_data}')\n",
    "print(f'[INFO] \\tTargets of training dataset: \\n{targets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Creating an Adaline...\n",
      "[INFO] \tRandom initial weights: [0.85687093 0.02633478 0.96817149 0.24457783 0.34848885]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Creating an Adaline\n",
    "print(f'\\n[INFO] Creating an Adaline...')\n",
    "number_of_epochs = 10000\n",
    "epsilon = 1e-5\n",
    "adaline1 = Adaline(num_features=4, learning_rate=0.01, epochs=number_of_epochs, epsilon=epsilon)\n",
    "print(f'[INFO] \\tOK!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Getting information about training dataset...\n",
      "[INFO] \tTraining dataset size = 35 4\n",
      "[INFO] \tLabels size = 35 1\n",
      "[INFO] \tLimit of epochs: 10000\n",
      "[INFO] \tEpsilon: 1e-05\n",
      "\n",
      "[INFO] Training the Adaline 1...\n",
      "[INFO] \tConverged after: 39 epochs.\n",
      "[INFO] \tFinal weights: [ 0.61687093  0.54973078  0.61733949 -0.08346417 -0.44539315]\n",
      "[INFO] \tTotal of epochs: 39\n",
      "[INFO] \tMean square error: [0.]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Training the Adaline\n",
    "print(f'\\n[INFO] Getting information about training dataset...')\n",
    "print(f'[INFO] \\tTraining dataset size = {training_data.shape[0]} {training_data.shape[1]}')\n",
    "print(f'[INFO] \\tLabels size = {targets.shape[0]} {targets.shape[1]}')\n",
    "print(f'[INFO] \\tLimit of epochs: {number_of_epochs}')\n",
    "print(f'[INFO] \\tEpsilon: {epsilon}')\n",
    "print(f'\\n[INFO] Training the Adaline 1...')\n",
    "adaline1.train(training_data, targets)\n",
    "print(f'[INFO] \\tOK!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Creating an new Adaline...\n",
      "[INFO] \tRandom initial weights: [0.73993445 0.71783308 0.88046206 0.71642348 0.55246439]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Creating an Adaline\n",
    "print(f'\\n[INFO] Creating an new Adaline...')\n",
    "number_of_epochs = 10000\n",
    "epsilon = 1e-5\n",
    "adaline2 = Adaline(num_features=4, learning_rate=0.01, epochs=number_of_epochs, epsilon=epsilon)\n",
    "print(f'[INFO] \\tOK!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Getting information about training dataset...\n",
      "[INFO] \tTraining dataset size = 35 4\n",
      "[INFO] \tLabels size = 35 1\n",
      "[INFO] \tLimit of epochs: 10000\n",
      "[INFO] \tEpsilon: 1e-05\n",
      "\n",
      "[INFO] Training the Adaline 2...\n",
      "[INFO] \tConverged after: 62 epochs.\n",
      "[INFO] \tFinal weights: [ 0.63993445  0.64771308  0.67042606 -0.07245452 -0.49953761]\n",
      "[INFO] \tTotal of epochs: 62\n",
      "[INFO] \tMean square error: [0.]\n",
      "[INFO] \tOK!\n"
     ]
    }
   ],
   "source": [
    "# Training the Adaline\n",
    "print(f'\\n[INFO] Getting information about training dataset...')\n",
    "print(f'[INFO] \\tTraining dataset size = {training_data.shape[0]} {training_data.shape[1]}')\n",
    "print(f'[INFO] \\tLabels size = {targets.shape[0]} {targets.shape[1]}')\n",
    "print(f'[INFO] \\tLimit of epochs: {number_of_epochs}')\n",
    "print(f'[INFO] \\tEpsilon: {epsilon}')\n",
    "print(f'\\n[INFO] Training the Adaline 2...')\n",
    "adaline2.train(training_data, targets)\n",
    "print(f'[INFO] \\tOK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Registre os resultados dos dois treinamentos na tabela a seguir:\n",
    "\n",
    "Tabela 3 - Resultados dos treinamentos (**tab_treinamento2.dat**):\n",
    "<table border=\"1\">\n",
    "\t<tr>\n",
    "\t\t<td rowspan=\"2\">Treinamento</td>\n",
    "\t\t<td colspan=\"5\">Vetor de Pesos Inicial</td>\n",
    "\t\t<td colspan=\"5\">Vetor de Pesos Final</td>\n",
    "\t\t<td rowspan=\"2\"> Número de Épocas</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>b</td>\n",
    "\t\t<td>w1</td>\n",
    "\t\t<td>w2</td>\n",
    "\t\t<td>w3</td>\n",
    "        <td>w4</td>\n",
    "\t\t<td>b</td>\n",
    "\t\t<td>w1</td>\n",
    "\t\t<td>w2</td>\n",
    "\t\t<td>w3</td>\n",
    "\t\t<td>w4</td>        \n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>1º (T1)</td>\n",
    "\t\t<td>0.85687093</td>\n",
    "\t\t<td>0.02633478</td>\n",
    "\t\t<td>0.96817149</td>\n",
    "\t\t<td>0.24457783</td>\n",
    "        <td>0.34848885</td>\n",
    "\t\t<td>0.61687093</td>\n",
    "\t\t<td>0.54973078</td>\n",
    "\t\t<td>0.61733949</td>\n",
    "\t\t<td>-0.08346417</td>\n",
    "        <td>-0.44539315</td>\n",
    "\t\t<td>39</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>2º (T1)</td>\n",
    "\t\t<td>0.73993445</td>\n",
    "\t\t<td>0.71783308</td>\n",
    "\t\t<td>0.88046206</td>\n",
    "\t\t<td>0.71642348</td>\n",
    "        <td>0.55246439</td>\n",
    "\t\t<td>0.63993445</td>\n",
    "\t\t<td>0.64771308</td>\n",
    "\t\t<td>0.67042606</td>\n",
    "\t\t<td>-0.07245452</td>\n",
    "        <td>-0.49953761</td>\n",
    "\t\t<td>62</td>\n",
    "\t</tr>\n",
    "</table>\n",
    "\n",
    "*Nota: os valores atuais dessa tabela se referem ao últimos treinamentos realizados. Caso os trechos de código acima sejam executados novamente, necessita-se atualizar a tabela.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Para os treinamentos realizados, aplique então a rede ADALINE para classificar e informar ao comutador se os sinais seguintes devem ser encaminhados para a válvula A ou B (ver tab_teste2.dat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Loading testing dataset...\n",
      "\t[INFO] OK!\n",
      "\n",
      "[INFO] Getting information about testing dataset...\n",
      "[INFO] \tTesting dataset size = 15\n"
     ]
    }
   ],
   "source": [
    "# # Testing the adaline\n",
    "print(f'\\n[INFO] Loading testing dataset...')\n",
    "file = open('tab_teste2.dat', 'r')\n",
    "results = list()\n",
    "\n",
    "for line in file:\n",
    "    columns = line.split()\n",
    "    columns = np.array(columns, dtype=float)\n",
    "    results.append(columns[:])\n",
    "    \n",
    "testing_data = np.array(results)\n",
    "print(f'\\t[INFO] OK!')\n",
    "\n",
    "print(f'\\n[INFO] Getting information about testing dataset...')\n",
    "# print(f'[INFO] Testing dataset size = {training_data.shape[0]}')\n",
    "print(f'[INFO] \\tTesting dataset size = {testing_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running testing data with Adaline 1...\n",
      "[INFO] \tInput: [0.9694 0.6909 0.4334 3.4965] -> Output: -1\n",
      "[INFO] \tInput: [0.5427 1.3832 0.639  4.0352] -> Output: -1\n",
      "[INFO] \tInput: [ 0.6081 -0.9196  0.5925  0.1016] -> Output: 1\n",
      "[INFO] \tInput: [-0.1618  0.4694  0.203   3.0117] -> Output: -1\n",
      "[INFO] \tInput: [ 0.187  -0.2578  0.6124  1.7749] -> Output: -1\n",
      "[INFO] \tInput: [ 0.4891 -0.5276  0.4378  0.6439] -> Output: 1\n",
      "[INFO] \tInput: [0.3777 2.0149 0.7423 3.3932] -> Output: 1\n",
      "[INFO] \tInput: [ 1.1498 -0.4067  0.2469  1.5866] -> Output: 1\n",
      "[INFO] \tInput: [0.9325 1.095  1.0359 3.3591] -> Output: 1\n",
      "[INFO] \tInput: [0.506  1.3317 0.9222 3.7174] -> Output: -1\n",
      "[INFO] \tInput: [ 0.0497 -2.0656  0.6124 -0.6585] -> Output: -1\n",
      "[INFO] \tInput: [0.4004 3.5369 0.9766 5.3532] -> Output: 1\n",
      "[INFO] \tInput: [-0.1874  1.3343  0.5374  3.2189] -> Output: -1\n",
      "[INFO] \tInput: [0.506  1.3317 0.9222 3.7174] -> Output: -1\n",
      "[INFO] \tInput: [ 1.6375 -0.7911  0.7537  0.5515] -> Output: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] Running testing data with Adaline 1...')\n",
    "# for inputs in training_data:\n",
    "for inputs in testing_data:\n",
    "    result = adaline1.predict(inputs)\n",
    "    print(f\"[INFO] \\tInput: {inputs} -> Output: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Running testing data with Adaline 2...\n",
      "[INFO] \tInput: [0.9694 0.6909 0.4334 3.4965] -> Output: -1\n",
      "[INFO] \tInput: [0.5427 1.3832 0.639  4.0352] -> Output: -1\n",
      "[INFO] \tInput: [ 0.6081 -0.9196  0.5925  0.1016] -> Output: 1\n",
      "[INFO] \tInput: [-0.1618  0.4694  0.203   3.0117] -> Output: -1\n",
      "[INFO] \tInput: [ 0.187  -0.2578  0.6124  1.7749] -> Output: -1\n",
      "[INFO] \tInput: [ 0.4891 -0.5276  0.4378  0.6439] -> Output: 1\n",
      "[INFO] \tInput: [0.3777 2.0149 0.7423 3.3932] -> Output: 1\n",
      "[INFO] \tInput: [ 1.1498 -0.4067  0.2469  1.5866] -> Output: 1\n",
      "[INFO] \tInput: [0.9325 1.095  1.0359 3.3591] -> Output: 1\n",
      "[INFO] \tInput: [0.506  1.3317 0.9222 3.7174] -> Output: -1\n",
      "[INFO] \tInput: [ 0.0497 -2.0656  0.6124 -0.6585] -> Output: -1\n",
      "[INFO] \tInput: [0.4004 3.5369 0.9766 5.3532] -> Output: 1\n",
      "[INFO] \tInput: [-0.1874  1.3343  0.5374  3.2189] -> Output: -1\n",
      "[INFO] \tInput: [0.506  1.3317 0.9222 3.7174] -> Output: -1\n",
      "[INFO] \tInput: [ 1.6375 -0.7911  0.7537  0.5515] -> Output: 1\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n[INFO] Running testing data with Adaline 2...')\n",
    "# for inputs in training_data:\n",
    "for inputs in testing_data:\n",
    "    result = adaline2.predict(inputs)\n",
    "    print(f\"[INFO] \\tInput: {inputs} -> Output: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabela 4 - Resultados com as saídas das saída (classes) para os dados de teste (**tab_teste2.dat**):\n",
    "\n",
    "<table border=\"1\">\n",
    "\t<tr>\n",
    "\t\t<td>Amostra</td>\n",
    "\t\t<td>x1</td>\n",
    "\t\t<td>x2</td>\n",
    "\t\t<td>x3</td>\n",
    "        <td>x4</td>\n",
    "\t\t<td>y (T1)</td>\n",
    "\t\t<td>y (T2)</td>        \n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>1</td>\n",
    "\t\t<td>0.9694</td>\n",
    "\t\t<td>0.6909</td>\n",
    "\t\t<td>0.4334</td>\n",
    "        <td>3.4965</td>\n",
    "\t\t<td>-1</td>\n",
    "\t\t<td>-1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>2</td>\n",
    "\t\t<td>0.5427</td>\n",
    "\t\t<td>1.3832</td>\n",
    "\t\t<td>0.639</td>\n",
    "\t\t<td>4.0352</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>3</td>\n",
    "\t\t<td>0.6081</td>\n",
    "\t\t<td>-0.9196</td>\n",
    "\t\t<td>0.5925</td>\n",
    "\t\t<td>0.1016</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>4</td>\n",
    "\t\t<td>-0.1618</td>\n",
    "\t\t<td>0.4694</td>\n",
    "\t\t<td>0.203</td>\n",
    "\t\t<td>3.0117</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>5</td>\n",
    "\t\t<td>0.187</td>\n",
    "\t\t<td>-0.2578</td>\n",
    "\t\t<td>0.6124</td>\n",
    "\t\t<td>1.7749</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>6</td>\n",
    "\t\t<td>0.4891</td>\n",
    "\t\t<td>-0.5276</td>\n",
    "\t\t<td>0.4378</td>\n",
    "\t\t<td>0.6439</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>7</td>\n",
    "\t\t<td>0.3777</td>\n",
    "\t\t<td>2.0149</td>\n",
    "\t\t<td>0.7423</td>\n",
    "\t\t<td>3.3932</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>8</td>\n",
    "\t\t<td>1.1498</td>\n",
    "\t\t<td>-0.4067</td>\n",
    "\t\t<td>0.2469</td>\n",
    "\t\t<td>1.5866</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>9</td>\n",
    "\t\t<td>0.9325</td>\n",
    "\t\t<td>1.095</td>\n",
    "\t\t<td>1.0359</td>\n",
    "\t\t<td>3.3591</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>10</td>\n",
    "\t\t<td>0.506</td>\n",
    "\t\t<td>1.3317</td>\n",
    "\t\t<td>0.9222</td>\n",
    "\t\t<td>3.7174</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>11</td>\n",
    "\t\t<td>0.0497</td>\n",
    "\t\t<td>-2.0656</td>\n",
    "\t\t<td>0.6124</td>\n",
    "\t\t<td>-0.6585</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr> \n",
    "\t<tr>\n",
    "\t\t<td>12</td>\n",
    "\t\t<td>0.4004</td>\n",
    "\t\t<td>3.5369</td>\n",
    "\t\t<td>0.9766</td>\n",
    "\t\t<td>5.3532</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>13</td>\n",
    "\t\t<td>-0.1874</td>\n",
    "\t\t<td>1.3343</td>\n",
    "\t\t<td>0.5374</td>\n",
    "\t\t<td>3.2189</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>14</td>\n",
    "\t\t<td>0.506</td>\n",
    "\t\t<td>1.3317</td>\n",
    "\t\t<td>0.9222</td>\n",
    "\t\t<td>3.7174</td>\n",
    "\t\t<td>-1</td>\n",
    "        <td>-1</td>\n",
    "    </tr>\n",
    "\t<tr>\n",
    "\t\t<td>15</td>\n",
    "\t\t<td>1.6375</td>\n",
    "\t\t<td>-0.7911</td>\n",
    "\t\t<td>0.7537</td>\n",
    "\t\t<td>0.5515</td>\n",
    "\t\t<td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr> \t\t\t\t\t\n",
    "</table>\n",
    "\n",
    "*Nota: os valores atuais dessa tabela se referem ao últimos testes realizados. Caso os trechos de código acima sejam executados novamente, necessita-se atualizar a tabela.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Um(a) estudante da disciplina de Redes Neurais e Aprendizado Profundo ficou empolgado(a) com o trabalho do Fisher sobre as flores Íris e resolveu propor uma versão automatizada para ele. Essa nova versão deveria ter dois módulos principais: um módulo de visão computacional e um módulo do tipo classificador neural. Caso você(s) fosse(m) esse(a) estudante, como você(s) desenvolveria(m) esse sistema? Descreva-o em detalhes. Use ilustração(ões) para valorizar o seu pré-projeto. Lembre-se que são três tipos de Íris (Virginica, Versicolor e Setosa) e que 4 parâmetros foram medidos pelo Fisher para cada uma das flores (comprimento e largura da Pétala, Comprimento e largura da Sépala)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Considere a base de dados encontrada em Irisdat.xlsx. Daí, pede-se: a) Treinar um PMC que classifique observações de flores íris em 3 espécies (Setosa, Versicolor e Virginica) usando como entradas as características SEPALLENGTH (SL), SEPALWIDTH (SW), PETALLENGTH (PL) e PETALWIDTH (PW). b) Estime SL a partir de SW, PL, PW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Considere a base de dados encontrada em engines.xlsx, em que ‘Fuel rate’ e ‘Speed’ são variáveis de entrada e ‘Torque’ e ‘Nitrous Oxide Emissions (NOE)’ são as variáveis de saída, respectivamente. Desenvolva três regressores. Um deles deve estimar conjuntamente o ‘Torque’ e o NOE. Já os outros dois devem estimar essas saídas separadamente (i.e. um estimará o Torque e o outro o NOE). Compare o desempenho das duas estratégias apontando qual delas apresenta uma maior capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Valendo-se da base de dados reais referente ao Volume de Vendas de Passagens (VVP) de uma companhia aérea norte-americana que se encontra no arquivo vvp.xlsx, pede-se: 1) Desenvolver um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente); 2) De posse da base de dados, remova a tendência linear presente na base de dados original. Desse modo, você conhecerá a série destendenciada e a tendência linear. Para a primeira série, desenvolva um previsor neural que receba como entradas os VVPs registrados nos instantes k-1 e k-12 (i.e. VVP(k-1) e VVP(k-12)) e que disponibilize na saída o VVP no instante corrente k (i.e. VVP(k)). O previsor deverá realizar previsões recursivas de 1 a 12 passos à frente (i.e., de um a doze meses à frente). Para a segunda (i.e., a tendência linear), preveja linearmente os próximos dozes pontos. Em seguida, some ponto a ponto as duas previsões e compare o desempenho dessa abordagem com a anterior apontando qual delas apresenta uma maior capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Procure na literatura 2 artigos que tratem do tema Sensores Inferenciais (ou Soft Sensors) para uma dada grandeza de seu interesse (e.g. temperatura, pressão, vazão, nível etc.) e que tenham sido publicados nos últimos 5 anos. Explique de forma sucinta o que foi desenvolvido pelos autores, referenciando-os. Sugestão: As principais informações de qualquer artigo geralmente se encontram no título, no resumo e nas conclusões. Ao ler esses três itens, o leitor tem uma boa ideia do que esperar daquele trabalho. A propósito, usualmente o leitor decidirá se lerá todo o artigo ou não com base na sua impressão a respeito desses três itens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d87e67db777b4b0db676edb6578e0de57a75ced3517006e5561808a12abc48f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
